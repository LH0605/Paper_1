import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage.filters import gaussian_filter1d
# epsilons = [0, 0.1, 0.3, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.3, 1.5, 1.7, 2.0] # linear loss
# epsilons = [0.1, 0.3, 0.5, 0.8, 0.9, 1.0, 1.3, 1.5, 2.0]
# epsilons = [0, 1., 3., 4., 6., 8., 10., 12.] # poisson
# epsilons = [0, 1., 3., 4., 7., 8., 10., 12.] # poisson alt
# epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 2.5, 3.0] # gaussian
epsilons = [0.1, 0.2, 0.3, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0] # gaussian reduced
# epsilons = [0, 1.0, 2.0, 5.0, 10.0, 20.0] # rbf
# epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 2.5, 3.0] # gpr
# epsilons = [0, 0.4, 0.6, 0.8, 1.1, 1.3, 1.5, 2.0, 2.5, 3.0] # svm

test_losses = [[1.87217845,2.05090994,1.85305356,1.6986966,1.68521177,1.64593692
,1.52736373,1.42933811,1.43847591,1.3958263,1.24055176,1.23186369
,1.23396586,1.18818658,1.1979245,1.12705262,1.07175855,1.06095093
,1.07950985,1.04309372,0.99098933,1.01058142,0.95468086,0.96428844
,0.9847488,1.00546786,0.93576833,0.89052768,0.90743744,0.9402835,]
,[1.88233368,2.17177345,1.97355661,1.8111086,1.74228212,1.61788916
,1.50494111,1.50458685,1.36674456,1.36366482,1.34214145,1.28728974
,1.25657608,1.24932127,1.16236971,1.17666034,1.07068802,1.10404553
,1.10989406,1.08788543,1.08117204,1.01678478,1.06631698,1.04599178
,1.0295555,1.01047825,0.96524606,0.98207062,0.92140868,0.93078411]
,[1.85652177,2.31630085,1.93489715,1.7269741,1.7295127,1.64139669
,1.63679766,1.56246592,1.44995257,1.46162195,1.47583816,1.35776421
,1.31019476,1.32347809,1.26261708,1.24452953,1.22707998,1.21603723
,1.18640018,1.15238375,1.16249784,1.16072172,1.02653834,1.10736911
,1.08858193,1.00353764,1.00342892,1.01787107,1.06066465,1.0396544,]
,[1.84797249,2.18283601,1.93907618,1.80894373,1.79031896,1.74285537
,1.59333001,1.6060996,1.49113299,1.53749376,1.4327291,1.46057091
,1.4164163,1.34923896,1.36896253,1.35780169,1.31533636,1.29391439
,1.26219849,1.23455501,1.27961766,1.17375464,1.15609492,1.12633246
,1.1792508,1.13627025,1.15362069,1.1206832,1.12522113,1.10857014]
,[1.85108459,2.26990001,1.96190214,1.91083149,1.77926342,1.73351914
,1.72743546,1.64286035,1.61910811,1.57849773,1.53144875,1.55067699
,1.43503897,1.46640496,1.46802422,1.4545241,1.45091139,1.40745248
,1.37279927,1.33830482,1.31729337,1.36601989,1.32959559,1.25687317
,1.34285631,1.34239765,1.32868947,1.21238259,1.24145412,1.26415414]
,[1.8564733,2.31588771,1.99518973,1.87532012,1.85697635,1.73479904
,1.73511246,1.70982654,1.58353481,1.66486206,1.61916512,1.63453268
,1.63241762,1.55946251,1.53204036,1.57091066,1.53336382,1.48960421
,1.4376873,1.42350998,1.42867309,1.39298353,1.43608237,1.38954845
,1.43041979,1.38729539,1.40038106,1.35075268,1.37059222,1.40595496]
,[1.86460658,2.31004075,1.90591685,1.92491847,1.92248021,1.872495
,1.80374135,1.76816316,1.78535093,1.71364656,1.67029157,1.66293671
,1.66780107,1.61146972,1.63356456,1.6324673,1.60556845,1.53603818
,1.53161449,1.62352902,1.55913442,1.5158425,1.50125248,1.50632728
,1.51761205,1.50024298,1.49569721,1.48462594,1.47437198,1.46677066]
,[1.89327018,2.17156852,2.04224247,1.99972945,1.93777977,1.82513113
,1.90667726,1.87224196,1.80014273,1.79301152,1.79336901,1.76427244
,1.7332134,1.76255021,1.74551813,1.72050278,1.71269175,1.70532375
,1.60975343,1.66524366,1.65617904,1.67241263,1.63857402,1.67782203
,1.64523356,1.59515798,1.63857145,1.58464152,1.65882081,1.59203303]
,[1.93537481,2.20892753,2.09123313,2.05200854,1.9534885,1.9846066
,1.88975468,1.90783033,1.84232926,1.87772455,1.84582472,1.89322657
,1.85101026,1.78669343,1.79471782,1.81040031,1.8476676,1.85027313
,1.8725698,1.75667651,1.78096192,1.76748348,1.80905451,1.76117772
,1.8110489,1.83236484,1.79433678,1.74061361,1.77533367,1.7133314,]
,[1.85808787,2.22990548,2.11108515,2.15611,2.10620967,1.97988403
,1.95519557,1.99984069,1.97450076,1.96549157,1.98605525,2.0352247
,1.99517047,1.95422942,1.94158597,1.93063374,2.02335635,1.9155028
,1.98098047,1.88254988,1.91912936,2.01857818,1.94395395,2.02621668
,2.01674974,1.95127955,1.98599555,1.969791,1.97002211,1.99765856]
,[1.87157163,2.27870573,2.12022723,2.16494809,2.17054899,2.12528396
,2.12216942,2.13867585,2.09625648,2.08194317,2.07067459,2.12300754
,2.16907811,2.17682713,2.1737554,2.21467941,2.18093234,2.15351419
,2.16840613,2.10980377,2.27473175,2.12006026,2.15454105,2.21837034
,2.23137433,2.22001248,2.30267597,2.23760235,2.14213703,2.16267619]
,[1.85146609,2.31100542,2.41339137,2.74385304,2.57495545,2.5815734
,2.6312576,2.63837795,2.83116845,3.07281288,2.92999801,3.02681341
,3.11703974,3.24607581,3.19175067,3.23013819,3.27651169,3.2778198
,3.28254126,3.40493738,3.34499484,3.38498156,3.38592831,3.3961201
,3.40200296,3.37261921,3.53648326,3.4515021,3.57254519,3.41855298]
,[1.87209933,2.35694072,2.7118702,2.8404702,2.90279282,3.11628654
,3.23639027,3.25161575,3.45445424,3.68399877,3.69560773,3.74546909
,3.98883838,4.00806705,4.00445668,4.09484062,4.28664965,4.16513362
,4.42608442,4.32426462,4.34144612,4.27985084,4.30155512,4.62114072
,4.37907471,4.65132319,4.70337384,4.6010018,4.6477354,4.53591264]
,[1.80319432,2.43823685,2.63565317,2.83043196,2.7958361,3.44850009
,3.27213089,3.57817753,3.89557145,3.87223655,4.07800765,4.34176533
,4.42260131,4.16000784,4.46267245,4.46807271,4.90665337,4.24471337
,4.89998073,4.90202405,4.8518927,4.84641776,5.0443063,5.29807013
,5.12603994,5.1414395,5.19701255,5.27150971,5.29013682,5.08943535]
,[1.8705807,2.32944507,2.69169623,3.03545527,3.03886926,3.31507141
,3.7388674,3.66274721,4.01493077,4.17768144,4.38313094,4.17984992
,4.63545689,4.71638782,4.73183272,4.4710362,4.80840775,4.83583597
,5.24299345,5.14978765,5.34131171,5.49699479,5.14133771,5.29024165
,5.59868203,5.81669592,5.54043598,5.80076547,5.57272706,5.73961666]]



del(test_losses[4])
del(test_losses[4])
del(test_losses[4])
del(test_losses[10])
del(test_losses[10])
del(test_losses[0])

if len(epsilons) != len(test_losses):
    print(len(epsilons), len(test_losses))
    raise Exception("should be the same, check epsilons")
TRAIN_SIZE = len(test_losses[0])
train_sizes = np.arange(1, TRAIN_SIZE+1)

plt.title("Gaussian Process Regression 1D with FGSM")
# plt.title("Linreg Loss 10D with FGM+sqrt")
plt.xlabel("Size of Training Dataset")
plt.ylabel("Test Loss")
for i in reversed(range(len(epsilons))):
    print('eps:', epsilons[i])
    ysmoothed = gaussian_filter1d(test_losses[i], sigma=1)
    plt.plot(train_sizes, ysmoothed, label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="right")
plt.savefig(f"gpr_fgsm_1d.png")
plt.clf()

# step = 3
# plt.title(f"SVM 10D with FGSM c=0.1 strong")
# plt.xlabel("Size of Training Dataset")
# plt.ylabel("Test Loss")
# plt.plot(train_sizes, test_losses[0], 'r--', label=f"Ɛ = 0")
# for i in range(len(epsilons[1+(2*step):])):
#     epsilon = epsilons[1+(2*step)+i]
#     plt.plot(train_sizes, gaussian_filter1d(test_losses[1+(2*step)+i], sigma=2), label=f"Ɛ = {epsilon}")
# plt.legend(loc="best")
# plt.savefig(f"svm_fgsm_10D_0.1_strong.png")

"""
# 1
plt.title("Linear Regression Gaussian")
plt.xlabel("Size of Training Dataset")
plt.ylabel("Test Loss")
for i in [1,2,3]: # range(len(epsilons)):
    print('eps:', epsilons[i])
    plt.plot(train_sizes, test_losses[i], label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="best")
plt.savefig(f"linreg_gaussian_fgsm_1d_weak.png")
plt.clf()

# 2
for i in [13, 14, 15, 16]:
    print('eps:', epsilons[i])
    plt.plot(train_sizes, test_losses[i], label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="best")
plt.savefig(f"linreg_gaussian_fgsm_1d_strong.png")
"""
