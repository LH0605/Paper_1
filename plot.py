import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage.filters import gaussian_filter1d
# epsilons = [0, 0.1, 0.3, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.3, 1.5, 1.7, 2.0] # linear loss
# epsilons = [0, 1., 3., 4., 6., 8., 10., 12.] # poisson
# epsilons = [0, 1., 3., 4., 7., 8., 10., 12.] # poisson alt
epsilons = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 2.5, 3.0] # gaussian
# epsilons = [0, 0.1, 0.2, 0.3, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0] # gaussian reduced

test_losses = [[0.10082152,0.09423483,0.08456386,0.07790036,0.070251,0.05961981
,0.06415213,0.06869998,0.09631329,0.10089905,0.07329587,0.05373081
,0.04609902,0.02866562,0.02185196,0.01911122,0.01818232,0.01373984
,0.01230208,0.01082923,0.01069176,0.00879912,0.00805694,0.00800089
,0.00729166,0.00678775,0.00642244,0.00585943,0.00558987,0.00509126]
,[0.09231122,0.08675705,0.08150762,0.07773055,0.07682012,0.06828739
,0.07333305,0.06629,0.05668041,0.04874788,0.04070937,0.03618144
,0.03014021,0.02546955,0.02342238,0.02038887,0.01819836,0.01622115
,0.01433363,0.0145119,0.01256668,0.01167688,0.01075774,0.00959696
,0.00908715,0.00856875,0.00794235,0.00808582,0.00768673,0.0070913,]
,[0.09408259,0.09260832,0.09221818,0.08501763,0.08574723,0.07598793
,0.07102767,0.06320959,0.05602579,0.05217859,0.04547758,0.04088021
,0.03774175,0.03445183,0.03123203,0.02947816,0.02798873,0.02536965
,0.02542741,0.02206326,0.0231502,0.02116737,0.02025068,0.01956155
,0.01848295,0.01788741,0.01723139,0.01688516,0.01608502,0.0160917,]
,[0.09798824,0.09458707,0.09457902,0.09030946,0.0863068,0.07788782
,0.07114595,0.06454423,0.06147496,0.05761863,0.05359746,0.05024236
,0.04818012,0.04605736,0.04377585,0.04331692,0.04278766,0.04024173
,0.04177565,0.03945104,0.03709546,0.03814832,0.03810145,0.03665279
,0.03547696,0.03486254,0.0348633,0.03461655,0.03422651,0.03394953]
,[0.09811397,0.09873592,0.09423151,0.09223899,0.08472311,0.07928262
,0.0723508,0.06867391,0.06389474,0.06174653,0.06076012,0.05806534
,0.05775608,0.0575436,0.05707852,0.05603859,0.05528316,0.05353775
,0.05398371,0.0522182,0.0526909,0.05482839,0.05389036,0.05338714
,0.05262274,0.0535976,0.05319626,0.05263881,0.05363479,0.05278364]
,[0.09868292,0.09733935,0.09838056,0.09135797,0.08471317,0.07780781
,0.07485561,0.07191927,0.07116634,0.06763999,0.067129,0.06643375
,0.06639306,0.06599085,0.06622151,0.06633469,0.06432183,0.06614545
,0.06615932,0.06563843,0.06577274,0.06510115,0.06476285,0.06537079
,0.0651289,0.06593383,0.06528831,0.06519009,0.06568671,0.0653912,]
,[0.10012965,0.10317224,0.09588471,0.0874137,0.08325885,0.07966229
,0.0768477,0.07481558,0.07435112,0.07343494,0.07338045,0.07265975
,0.07172887,0.07206893,0.0726538,0.07138117,0.07157144,0.07219193
,0.07281801,0.07176981,0.07313676,0.07214575,0.07188115,0.07302131
,0.07263261,0.07188149,0.07201168,0.07234231,0.07313235,0.07257462]
,[0.10215766,0.10015078,0.09431892,0.08874774,0.0843065,0.08040667
,0.07949594,0.07980087,0.07827366,0.07711203,0.07770446,0.07679004
,0.07697585,0.07763016,0.07639075,0.07693368,0.07720235,0.07685775
,0.07695154,0.07730273,0.07782685,0.07818218,0.0775581,0.0783789
,0.07801269,0.07817033,0.07758975,0.07835354,0.07788547,0.07798211]
,[0.10032674,0.10206718,0.09564765,0.08901164,0.08529076,0.08256653
,0.08210172,0.080776,0.08052436,0.08119946,0.08126426,0.08118733
,0.08051797,0.08098623,0.0812606,0.08194637,0.08154432,0.08161851
,0.08102457,0.08185728,0.08223895,0.08226802,0.08211569,0.08217625
,0.08309852,0.08256469,0.08313639,0.08330394,0.08310804,0.08335292]
,[0.10355621,0.09948209,0.09269775,0.08714419,0.0854378,0.08451927
,0.08431386,0.08380902,0.08327773,0.08361434,0.08422118,0.08422459
,0.08440315,0.08435974,0.08486104,0.08516144,0.08452661,0.08536541
,0.08583896,0.0850796,0.08550564,0.0858074,0.08632347,0.0864121
,0.0860495,0.08665751,0.0865248,0.08719116,0.08698424,0.08720575]
,[0.10077179,0.10055201,0.09211731,0.08891914,0.086336,0.08624867
,0.08620104,0.08567663,0.08661704,0.08628169,0.08612171,0.08652389
,0.08731003,0.08595668,0.08722873,0.08722026,0.08770131,0.08860289
,0.08827479,0.08855875,0.08842346,0.08848533,0.08967786,0.08994987
,0.08960277,0.08986333,0.0894751,0.09011199,0.08978721,0.09021587]
,[0.10167791,0.09483025,0.09228093,0.09267165,0.09212169,0.09294321
,0.09321277,0.09384396,0.0939918,0.09476357,0.09516601,0.09545317
,0.09595791,0.09543808,0.09634304,0.09645954,0.09677381,0.09677584
,0.09704822,0.09692354,0.09735151,0.097346,0.09728656,0.09748738
,0.09774327,0.09782024,0.09804524,0.0979345,0.0980866,0.09808893]
,[0.09909006,0.09484483,0.09540624,0.09578879,0.09615002,0.09719566
,0.09733141,0.09779268,0.09813667,0.09839514,0.09839468,0.09875155
,0.0985239,0.09873326,0.09868476,0.09885773,0.098861,0.09901394
,0.09905513,0.09892463,0.09911332,0.09909055,0.09901497,0.09908642
,0.09905532,0.09915721,0.09912794,0.09907526,0.09911113,0.09909488]
,[0.09780521,0.09660613,0.09776969,0.09827658,0.09828556,0.09879164
,0.09897044,0.09920486,0.09917608,0.09930865,0.09934814,0.0994421
,0.09931977,0.09927489,0.09941931,0.09936835,0.09939214,0.09937024
,0.09941398,0.09948168,0.0993613,0.0994448,0.09941351,0.09935035
,0.09941083,0.09944051,0.09946137,0.09945524,0.09935812,0.09944166]
,[0.0979143,0.09841462,0.09869916,0.09902058,0.09939179,0.0994289
,0.0995083,0.09945334,0.09945914,0.09953239,0.09956953,0.09956765
,0.0995033,0.09947008,0.09955979,0.0995995,0.09955182,0.09950569
,0.09951131,0.09954878,0.09949707,0.09953691,0.09954736,0.09957261
,0.09954631,0.09954794,0.09957972,0.09950872,0.09950166,0.09952836]]


if len(epsilons) != len(test_losses):
    print(len(epsilons), len(test_losses))
    raise Exception("should be the same, check epsilons")
TRAIN_SIZE = len(test_losses[0])
train_sizes = np.arange(1, TRAIN_SIZE+1)

plt.title("Linear Regression 10D Gaussian with FGSM")
plt.xlabel("Size of Training Dataset")
plt.ylabel("Test Loss")
for i in range(len(epsilons)):
    print('eps:', epsilons[i])
    ysmoothed = gaussian_filter1d(test_losses[i], sigma=1)
    plt.plot(train_sizes, ysmoothed, label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="right")
plt.savefig(f"linreg_gaussian_fgsm_10d_all.png")
plt.clf()

"""
# 1
plt.title("Linear Regression Gaussian")
plt.xlabel("Size of Training Dataset")
plt.ylabel("Test Loss")
for i in [1,2,3]: # range(len(epsilons)):
    print('eps:', epsilons[i])
    plt.plot(train_sizes, test_losses[i], label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="best")
plt.savefig(f"linreg_gaussian_fgsm_1d_weak.png")
plt.clf()

# 2
for i in [13, 14, 15, 16]:
    print('eps:', epsilons[i])
    plt.plot(train_sizes, test_losses[i], label=f"Ɛ = {epsilons[i]}")
plt.legend(loc="best")
plt.savefig(f"linreg_gaussian_fgsm_1d_strong.png")
"""
